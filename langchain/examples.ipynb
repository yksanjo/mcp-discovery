{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCP Discovery Tool for LangChain\n",
    "\n",
    "This notebook demonstrates how to use the MCP Discovery tool to enable LangChain agents to dynamically discover and select tools based on their task requirements.\n",
    "\n",
    "## What is MCP Discovery?\n",
    "\n",
    "MCP Discovery provides a semantic search API over Model Context Protocol (MCP) servers, allowing agents to:\n",
    "- Find relevant tools based on natural language queries\n",
    "- Compare server performance metrics\n",
    "- Get installation instructions automatically\n",
    "- Discover new capabilities dynamically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install langchain langchain-openai requests\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from mcp_discovery_tool import MCPDiscoveryTool, create_mcp_discovery_tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain import hub\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Usage\n",
    "\n",
    "Simply use the tool to discover MCP servers based on a capability description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discovery tool\n",
    "discovery_tool = create_mcp_discovery_tool()\n",
    "\n",
    "# Search for database-related MCP servers\n",
    "result = discovery_tool.run(\"PostgreSQL database access\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Different Search Queries\n",
    "\n",
    "The tool supports various types of capability searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for different capabilities\n",
    "queries = [\n",
    "    \"send emails\",\n",
    "    \"file system operations\",\n",
    "    \"weather data API\",\n",
    "    \"web scraping\",\n",
    "    \"cloud storage\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print('='*60)\n",
    "    result = discovery_tool.run(query)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Agent with MCP Discovery\n",
    "\n",
    "Integrate MCP Discovery into a LangChain agent so it can find tools dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API key (required for agent)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Create LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "# Create tools list with MCP Discovery\n",
    "tools = [discovery_tool]\n",
    "\n",
    "# Get the ReAct prompt from hub\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "# Create agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Agent discovers database tools when needed\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"I need to work with a PostgreSQL database. What tools are available?\"\n",
    "})\n",
    "\n",
    "print(\"\\nAgent Response:\")\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Using Performance Metrics for Selection\n",
    "\n",
    "The tool returns performance metrics that agents can use for decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent compares multiple options based on metrics\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": (\n",
    "        \"I need to send emails. Find me the best email MCP server \"\n",
    "        \"with the lowest latency and highest uptime.\"\n",
    "    )\n",
    "})\n",
    "\n",
    "print(\"\\nAgent Response:\")\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Custom API Endpoint\n",
    "\n",
    "You can point to a custom MCP Discovery API instance if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use custom API endpoint (e.g., for testing or private deployments)\n",
    "custom_tool = create_mcp_discovery_tool(\n",
    "    api_url=\"https://your-custom-mcp-discovery.example.com\"\n",
    ")\n",
    "\n",
    "result = custom_tool.run(\"file storage\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Error Handling\n",
    "\n",
    "The tool gracefully handles API errors and timeouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: No matching servers found\n",
    "result = discovery_tool.run(\"extremely obscure nonexistent capability xyz123\")\n",
    "print(result)\n",
    "\n",
    "# The agent can handle this and adjust its approach\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"Find me a tool for quantum encryption. If none exists, suggest alternatives.\"\n",
    "})\n",
    "print(\"\\nAgent Response:\")\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: Multi-Step Agent Workflow\n",
    "\n",
    "An agent can discover multiple tools in sequence based on a complex task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex task requiring multiple tool discoveries\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": (\n",
    "        \"I need to build a workflow that: \"\n",
    "        \"1) Fetches data from a database, \"\n",
    "        \"2) Processes it with file operations, and \"\n",
    "        \"3) Sends the results via email. \"\n",
    "        \"What MCP servers should I use for each step?\"\n",
    "    )\n",
    "})\n",
    "\n",
    "print(\"\\nAgent Response:\")\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Dynamic Tool Discovery**: Agents can find tools based on task needs rather than pre-configured lists\n",
    "2. **Performance Metrics**: Make informed decisions based on latency and uptime data\n",
    "3. **Installation Info**: Get immediate setup instructions for discovered servers\n",
    "4. **Semantic Search**: Natural language queries work well for capability matching\n",
    "5. **Error Resilient**: Graceful handling of missing results or API issues\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore the [MCP Discovery API documentation](https://github.com/yksanjo/mcp-discovery)\n",
    "- Browse available MCP servers at the [MCP Registry](https://github.com/mcp)\n",
    "- Integrate with your existing LangChain agents\n",
    "- Contribute additional MCP servers to expand the ecosystem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
